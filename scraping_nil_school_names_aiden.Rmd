---
title: "Scraping NIL School Names"
author: "Aidan Hughes"
date: "`r Sys.Date()`"
output: html_document
---

```{r}

# Load required libraries
library(httr)
library(rvest)
library(dplyr)

```

```{r}
# URL of the website to scrape
fullurl <- 'https://nil.store/'
```

```{r}
# Fetch the webpage content
response <- GET(fullurl)
html_content <- content(response, as = "text")
```

```{r}
# Parse the HTML content using rvest
soup <- read_html(html_content)
```

```{r}
# Find the specific div containing the school names and URLs
schools_nav <- html_node(soup, css = "div.mega_menu_main#schools-nav")
```


```{r}
# Check if the element is found
if (!is.null(schools_nav)) {
  # Find all the list items within this div
  school_list_items <- html_nodes(schools_nav, css = "li.only_link")
  
  # Extract the school names and URLs from the list items
  schools <- lapply(school_list_items, function(item) {
    link <- html_node(item, "a")
    if (!is.null(link)) {
      school_name <- html_text(link, trim = TRUE)
      school_url <- trimws(html_attr(link, "href"))
      list(name = school_name, url = school_url)
    }
  })
  
  # Filter out NULL values
  schools <- Filter(Negate(is.null), schools)
  
  # Create a data frame from the extracted data
  schools_df <- do.call(rbind, lapply(schools, as.data.frame)) %>%
    as.data.frame(stringsAsFactors = FALSE)
  
  print(schools_df)
}
  
  schools_df[68, 2] = "https://xavier.nil.store"
  
print(schools_df$url)

```


```{r}

# Load necessary libraries
library(rvest)
library(httr)
library(dplyr)

# Initialize an empty list to store athlete names
```


```{r}
schools_df_2 <- schools_df %>%
  slice(-25)
```


```{r}
# Initialize a list to store the results
scraped_results <- list()

# Iterate over each row in the data frame
for (i in 1:nrow(schools_df_2)) {
  name <- schools_df_2$name[i]
  url <- trimws(schools_df_2$url[i])  # Remove any leading/trailing spaces
  webpage <- read_html(url)
  scraped_data <- html_text(html_nodes(webpage, xpath = "//div[contains(@class, 'nested-mobile-menu-heading-container') and contains(@class, 'athlete')]//following-sibling::div[@class='nested-mobile-menu']//li[@class='only_link']//a[@class='color-text']"), trim = TRUE)
  scraped_results[[i]] <- list(name = name, url = url, data = scraped_data)
}

# Combine the list of results into a single data frame
scraped_results_df <- bind_rows(scraped_results)

# Print the results
print(scraped_results_df)

```
```{r}
by_school <- scraped_results_df %>%
  group_by(name) %>%
  summarize(
    athletes = n()
  )
```

```{r Where I accidentally made a dataframe of Logos}
# Initialize a list to store the results
Logos <- list()

for (i in 1:nrow(schools_df_2)) {
  name <- schools_df_2$name[i]
  url <- trimws(schools_df_2$url[i])
  webpage <- read_html("https://nil.store")
  school <- html_text(html_nodes(webpage, xpath = "//li[@class='only_link']/a[@class='color-text']"))
  logo <- html_attr(html_nodes(webpage, xpath = "//li[@class='only_link']/a/img"), "src")
}

# Create a data frame with the extracted data
Logos <- data.frame(School = school, LogoLink = logo) %>%
  slice(1:68) 

Logos$LogoLink <- paste("https:", Logos$LogoLink, sep = "")


```


```{r Adding Conferences + Other info to spreadsheet}
ncaa_url <- "https://en.wikipedia.org/wiki/List_of_NCAA_Division_I_institutions"

division1 <- read_html(ncaa_url) 

ncaa_tables <- division1 %>% 
  html_table(fill = TRUE)

# Display the number of tables extracted
length(ncaa_tables)

# Display the first few rows of each table to find the one you need
for (i in 1:length(ncaa_tables)) {
  cat("Table", i, ":\n")
  print(head(ncaa_tables[[i]]))
  cat("\n\n")
}

my_ncaa_table <- ncaa_tables[[2]]
```

```{r}
colnames(my_ncaa_table) <- c("School", "Common Name", "Nickname", "City","State", "Type", "Subdivision", "Primary")
colnames(by_school)<- c("Common Name","Number_Athletes")

my_ncaa_table <- my_ncaa_table %>%
  slice(-1)

#Cleaning Before Join

my_ncaa_table[25,2] = "California Baptist"
my_ncaa_table[63,2] = "ETSU"
my_ncaa_table[69,2] = "FGCU"
my_ncaa_table[280,2]= "Mizzou"
my_ncaa_table[304,2]= "Pitt"
my_ncaa_table[179,2]="SDSU"

# Install and load the dplyr package
library(dplyr)

# Left join
full_school_info <- left_join(by_school, my_ncaa_table, by = "Common Name") 

full_school_info$Primary <- gsub("\\[.*?\\]", "", full_school_info$Primary)
full_school_info$City <- gsub("\\[.*?\\]", "", full_school_info$City)
full_school_info$School <- gsub("\\[.*?\\]", "", full_school_info$School)
full_school_info$Type <- gsub("\\[.*?\\]", "", full_school_info$Type)

print(full_school_info)

```
```{r Starting Comparison}

#STATE LEVEL
states <- full_school_info %>%
  select("School","Common Name", "Number_Athletes", "State") 

states_compared <- states %>%
  group_by(State) %>%
  summarise(
    number_of_schools = n(),
    total_athletes = sum(Number_Athletes))

#PUBLIC V. PRIVATE
pubpriv <- full_school_info %>%
  select("School","Common Name", "Number_Athletes", "Type")

pubpriv_compared <- pubpriv %>%
  group_by(Type) %>%
  summarise(
    number_of_schools = n(),
    total_athletes = sum(Number_Athletes)
    )

#LEVEL OF DIVISION 1

subdivision1 <- full_school_info %>%
  select("School","Common Name", "Number_Athletes", "Subdivision")

subdivision_compared <- subdivision1 %>%
  group_by(Subdivision) %>%
  summarise(
    number_of_schools = n(),
    total_athletes = sum(Number_Athletes)
    )

#CONFERENCE

conferences <- full_school_info %>%
  select("School","Common Name", "Number_Athletes", "Subdivision", "Primary")

conferences_compared <- conferences %>%
  group_by(Primary) %>%
  summarise(
    number_of_schools = n(),
    total_athletes = sum(Number_Athletes)
    )

conferences_and_sub <- conferences %>%
  group_by(Primary, Subdivision) %>%
  summarise(
    number_of_schools = n(),
    total_athletes = sum(Number_Athletes)
    )
```


