---
title: "Scraping UNC NIL Athletes"
author: "Aidan Hughes"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(httr)
library(rvest)
library(dplyr)
library(xml2)
```


```{r}

# Load the HTML content from the website
uncurl <- "https://unc.nil.store/"
unchtml <- read_html(uncurl)

# Find the specific parent node
unc_parent_node <- unchtml %>%
  html_node(xpath = "//div[contains(@class, 'nested-mobile-menu-heading-container athlete')]//following-sibling::div[@class='nested-mobile-menu']")

# Extract all the nested li elements within the parent node
unc_nested_li_elements <- unc_parent_node %>%
  html_nodes("ul > li > ul > li")

# Extract the athlete names and URLs from the nested li elements
unc_athletes <- unc_nested_li_elements %>%
  html_nodes("a") %>%
  {data.frame(
    name = html_text(., trim = TRUE),
    site = paste0("https://unc.nil.store", html_attr(., "href")),
    school = "North Carolina"
    )}


```

```{r}
# Initialize a list to store the results
gender_sport <- list()

for (i in 1:nrow(schools_df_2)) {
  name <- schools_df_2$name[i]
  url <- trimws(schools_df_2$url[i])  # Remove any leading/trailing spaces
  webpage <- read_html(url)
  scraped_data <- html_text(html_nodes(webpage, xpath= "//div[@class='nested-mobile-menu']//li//a[@class='color-text']/@href"))
  gender_sport[[i]] <- list(name = name, url = url, data = scraped_data)
}

# Combine the list of results into a single data frame
gender_sport_df <- bind_rows(gender_sport) %>%
  
# Print the results
print(gender_sport_df)
```
```{r}
# Assuming you already have the 'gender_sport_df' dataframe

# Load the dplyr package
library(dplyr)

# Define a function to extract the desired portion of the URL
extract_url <- function(url, data) {
  parts <- unlist(strsplit(url, "/"))
  combined_url <- paste(parts[1:3], collapse = "/")
  return(paste0(combined_url, data))
}

# Apply the function to the 'url' column using mutate and rowwise
gender_sport_df <- gender_sport_df %>%
  rowwise() %>%
  mutate(combined_url = extract_url(url, data))

# Print the updated dataframe
print(gender_sport_df, 590:595)

```
```{r}
gender_sport_df <- gender_sport_df %>% filter(
    !grepl("shop-by-sport$", combined_url) & 
      !grepl("jerseys", combined_url) & 
      !grepl("jersey", combined_url) & 
      !grepl("sports", combined_url) & 
      !grepl("onit-trading-card", combined_url) & 
      !grepl("exclusive-drops", combined_url) & 
      !grepl("postseason-apparel", combined_url) & 
      !grepl("limited-releases", combined_url) & 
      !grepl("limited-release", combined_url) & 
      !grepl("trading-cards", combined_url) &
      !grepl("bulldog-initiative", combined_url) &
      !grepl("legacy", combined_url) & 
      !grepl("tees", combined_url) &
      !grepl("dawg-mentality-collection", combined_url) &
      !grepl("big-red-helmet-collection", combined_url) &
      !grepl("future", combined_url) &
      !grepl("releases", combined_url) &
      !grepl("volleyball-day", combined_url) &
      !grepl("jackets", combined_url) &
      !grepl("locker-room", combined_url) &
      !grepl("legacy", combined_url) &
      !grepl("merch", combined_url) &
      !grepl("coming-soon", combined_url) &
      !grepl("https://nil.shop/search", combined_url) &
      !grepl("collective", combined_url) &
      !grepl("search", combined_url) &
      !grepl("champions", combined_url) &
       !grepl("shirseys", combined_url) &
       !grepl("https://nil.store/pages/pitt/", combined_url) &
       !grepl("champion", combined_url) &
       !grepl("four", combined_url) &
       !grepl("eight", combined_url) &
      !grepl("sixteen", combined_url) &
      !grepl("stop", combined_url) &
      !grepl("apparel", combined_url) &
      !grepl("raglan", combined_url) &
      !grepl("https://nil.store/pages/baylor/pages/baylor", combined_url) &
      url!= combined_url &
      substr(combined_url, nchar(combined_url), nchar(combined_url)) != "/" &
      substr(combined_url, nchar(combined_url), nchar(combined_url)) != "#"
      )
```

```{r}

library(dplyr)

# Create the third dataframe athlete_urls
athlete_urls <- anti_join(gender_sport_df, all_sport_pages, by = "combined_url")

# View the resulting dataframe
print(athlete_urls)

# Define the row indices to be removed
rows_to_remove <- c(9907, 9662, 9574, 9516, 9463, 9384, 9328:9330, 9301, 9197, 
                    9138, 9088, 9034, 8490, 8429, 8367, 8297, 8215, 8167, 8106, 
                    7004, 5293, 5292, 5265, 5182, 3615, 3614, 3545, 3422:3424, 
                    3126:3128, 2740, 2741, 2492, 2209, 2210, 2179:2181, 2136:2141, 
                    2097, 2006, 1877, 1818, 1817, 1816, 1767, 1715, 1662, 1242, 
                    645, 578, 516, 453)

# Remove the specified rows from the dataframe
athlete_urls <- athlete_urls[-rows_to_remove, ]

# View the resulting dataframe
print(athlete_urls)
```

Extracting names 
```{r}


# Create the new column athlete_ext, remove numbers, and replace hyphens with spaces
athlete_urls <- athlete_urls %>%
  mutate(athlete_ext = str_extract(combined_url, "[^/]+$")) %>%
  mutate(athlete_ext = gsub("[0-9]", "", athlete_ext)) %>%
  mutate(athlete_ext = gsub("-", " ", athlete_ext)) %>%
   mutate(athlete_ext = str_to_title(athlete_ext))

# View the resulting dataframe
print(athlete_urls)


```
Converting name.
```{r}


```


```{r}
# Assuming your data frame is named 'scraped_results_df' and the column with names is 'data'
# Assuming your data frame is named 'scraped_results_df' and the column with names is 'data'
# Install and load necessary packages

library(tidyr)

# Sample data frame for testing

# Use the separate function to split the 'data' column into 'Lastname' and 'Firstname'
scraped_results_df <- scraped_results_df %>%
  separate(data, into = c("Lastname", "Firstname"), sep = ",\\s*")
```

```{r}

library(stringi)

# Function to format names
format_names <- function(firstname, lastname) {
  # Replace apostrophes with hyphens
  firstname <- gsub("'", "-", firstname)
  firstname <- gsub("’", "-", firstname)
  lastname <- gsub("'", "-", lastname)
  lastname <- gsub("’", "-", lastname)
  # Replace accented characters with non-accented equivalents and convert to lowercase
  firstname <- tolower(stri_trans_general(firstname, "Latin-ASCII"))
  lastname <- tolower(stri_trans_general(lastname, "Latin-ASCII"))
  # Join two-word values with a hyphen
  firstname_parts <- strsplit(firstname, " ")[[1]]
  lastname_parts <- strsplit(lastname, " ")[[1]]
  firstname <- paste(firstname_parts, collapse = "-")
  lastname <- paste(lastname_parts, collapse = "-")
  # Combine firstname and lastname with a hyphen
  matching_part <- paste(firstname, lastname, sep = "-")
  return(matching_part)
}

# Create the 'matching_part' column
scraped_results_df <- scraped_results_df %>%
  rowwise() %>%
  mutate(matching_part = format_names(Firstname, Lastname))

# Print the final dataframe
print(scraped_results_df)


```

```{r}
athletes_to_use <- scraped_results_df %>%
  select(c("name","Firstname","Lastname", "matching_part"))

gender_sport_df <- gender_sport_df %>%
  select(c("name", "url","data","combined_url"))
```

```{r}
# Preprocess the columns to extract the shared piece
# Initialize an empty dataframe to store the merged results

matched_rows_list <- vector("list", length = nrow(athletes_to_use))

# Iterate through each row in scraped_results_df
for (i in 1:nrow(athletes_to_use)) {
  # Extract the shared piece from the matching-part column in scraped_results_df
  shared_piece <- athletes_to_use$matching_part[i]
  
  # Find matching rows in gender_sport_df based on the extracted shared piece
  matching_rows <- gender_sport_df[grepl(shared_piece, gender_sport_df$combined_url), ]
  
  # Ensure that the entire shared piece is found in the URLs
  matching_rows <- matching_rows[grepl(paste0("\\b", shared_piece, "\\b"), matching_rows$combined_url), ]
  
  # Append matching rows to the list
  matched_rows_list[[i]] <- matching_rows
}

# Add the list column to scraped_results_df
athletes_to_use$matched_rows <- matched_rows_list
```

```{r}
library(tidyr)

athletes_to_use <- athletes_to_use%>%
    unnest_wider(matched_rows, names_sep = "_")

```


```{r}
print("Position of missing values ")
which(is.n(athletes_to_use$matched_rows_combined_url))
 
# count total missing values 
print("Count of total missing values  ")
sum(is.na(athletes_to_use$matched_rows_combined_url))
```


```{r}
library(rvest)
library(dplyr)

library(rvest)
library(dplyr)

mens_sport <- list()
womens_sport <- list()

for (i in 1:nrow(schools_df_2)) {
  name <- schools_df_2$name[i]
  url <- trimws(schools_df_2$url[i])  # Remove any leading/trailing spaces
  webpage <- read_html(url)
  
  mens_teams <- webpage %>%
    html_nodes("div.nested-mobile-menu li:contains(\"Men's\") ul li") %>%
    html_text() %>%
    trimws()  # Remove leading/trailing spaces from team names
  
  womens_teams <- webpage %>%
    html_nodes("div.nested-mobile-menu li:contains(\"Women's\") ul li") %>%
    html_text() %>%
    trimws()  # Remove leading/trailing spaces from team names
  
  mens_sport[[i]] <- data.frame(name = name, url = url, team = mens_teams, stringsAsFactors = FALSE)
  womens_sport[[i]] <- data.frame(name = name, url = url, team = womens_teams, stringsAsFactors = FALSE)
}

# Combine the list of results into separate data frames for men's and women's teams
mens_sport_df <- bind_rows(mens_sport) %>%
  filter(
    !grepl("Florida Atlantic", name) & 
    !grepl("Utah State", name)
  )

womens_sport_df <- bind_rows(womens_sport) %>%
  filter(
    !grepl("Florida Atlantic", name) & 
    !grepl("Utah State", name)
  )

# Perform a full join to combine the men's and women's teams
testing_urls_df <- full_join(mens_sport_df, womens_sport_df, by = c("name", "url"), suffix = c("_mens", "_womens"))



```


```{r}



```
```{r}

```



```{r}
library(rvest)
library(dplyr)
library(tidyr)

# Initialize a list to store the results
crying_if_this_works <- list()

for (i in 1:nrow(schools_df_2)) {
  name <- schools_df_2$name[i]
  url <- trimws(schools_df_2$url[i])  # Remove any leading/trailing spaces
  
  # Remove trailing slash from the URL if present
  url <- sub("/$", "", url)
  
  webpage <- read_html(url)
  scraped_data <- html_text(html_nodes(webpage, xpath= "//div[@class='nested-mobile-menu']//li//a[@class='color-text']/@href"))
  
  # Combine url and scraped_data
  combined_urls <- paste0(url, scraped_data)
  
  crying_if_this_works[[i]] <- data.frame(
    name = name,
    url=url,
    combined_url = combined_urls,
    stringsAsFactors = FALSE
  )
}

# Combine the list of results into a single data frame
crying_if_this_works_df <- bind_rows(crying_if_this_works) %>%
  filter(
    !grepl("shop-by-sport$", combined_url) & 
      !grepl("jerseys", combined_url) & 
      !grepl("jersey", combined_url) & 
      !grepl("sports", combined_url) & 
      !grepl("onit-trading-card", combined_url) & 
      !grepl("exclusive-drops", combined_url) & 
      !grepl("postseason-apparel", combined_url) & 
      !grepl("limited-releases", combined_url) & 
      !grepl("limited-release", combined_url) & 
      !grepl("trading-cards", combined_url) &
      !grepl("bulldog-initiative", combined_url) &
      !grepl("legacy", combined_url) & 
      !grepl("tees", combined_url) &
      !grepl("dawg-mentality-collection", combined_url) &
      !grepl("big-red-helmet-collection", combined_url) &
      !grepl("future", combined_url) &
      !grepl("releases", combined_url) &
      !grepl("volleyball-day", combined_url) &
      !grepl("jackets", combined_url) &
      !grepl("locker-room", combined_url) &
      !grepl("legacy", combined_url) &
      !grepl("merch", combined_url) &
      !grepl("coming-soon", combined_url) &
      !grepl("https://nil.shop/search", combined_url) &
      !grepl("collective", combined_url) &
      !grepl("search", combined_url) &
      !grepl("champions", combined_url) &
       !grepl("shirseys", combined_url) &
       !grepl("https://nil.store/pages/pitt/", combined_url) &
       !grepl("champion", combined_url) &
       !grepl("four", combined_url) &
       !grepl("eight", combined_url) &
      !grepl("sixteen", combined_url) &
      !grepl("stop", combined_url) &
      !grepl("apparel", combined_url) &
      !grepl("raglan", combined_url) &
      !grepl("https://nil.store/pages/baylor/pages/baylor", combined_url) &
      url!= combined_url &
      substr(combined_url, nchar(combined_url), nchar(combined_url)) != "/" &
      substr(combined_url, nchar(combined_url), nchar(combined_url)) != "#"
      )
```

```{r}
clean_all_urls <- crying_if_this_works_df %>%
   mutate(combined_url = sub("/pages/", "/", combined_url))
  

```

```{r}
# Separate sport pages and athlete pages
sport_pages <- 
  
athlete_pages <-
```

HERE WE GO AGAIN!!
```{r}
url <- "https://unc.nil.store/"
html <- read_html(url)

mens_sports <- html %>%
    html_nodes(".nested-mobile-menu li:contains(\"Men's\") li.only_link a.color-text") %>%
    html_attr("href")
```

```{r}
library(tidyverse)
write_csv(schools_df_2, "schools_df_2.csv")
```

```{r}
library(tidyr)
library(tidyverse)

schools_df_2 <- schools_df_2 %>%
  slice(-58) %>%
  slice(-18)
```

```{r}

mens_sports_df <- list()

for (i in 1:nrow(schools_df_2)) {
  name <- schools_df_2$name[i]
  url <- trimws(schools_df_2$url[i])
  
  tryCatch({
    html <- read_html(url)
    mens_sports <- html %>%
      html_nodes(".nested-mobile-menu li:contains(\"Men's\") li.only_link a.color-text") %>%
      html_attr("href")
    
    if (length(mens_sports) > 0) {
      mens_sports_df[[name]] <- mens_sports
    } else {
      mens_sports_df[[name]] <- NA
    }
  }, error = function(e) {
    mens_sports_df[[name]] <- NA
    warning(paste("Error occurred for", name, ":", e$message))
  })
}

# Unpack the list column and convert to a DataFrame
mens_sports_df <- mens_sports_df %>%
  enframe(name = "name", value = "mens_sports") %>%
  unnest(mens_sports)

# Join with the schools_df_2 DataFrame to include the base URL
mens_sports_df <- mens_sports_df %>%
  left_join(schools_df_2, by = "name") %>%
  mutate(gender = "Men's")

# Print the resulting DataFrame
print(mens_sports_df)

  
```

```{r}
womens_sports_df <- list()

for (i in 1:nrow(schools_df_2)) {
  name <- schools_df_2$name[i]
  url <- trimws(schools_df_2$url[i])
  
  tryCatch({
    html <- read_html(url)
    womens_sports <- html %>%
      html_nodes(".nested-mobile-menu li:contains(\"Women's\") li.only_link a.color-text") %>%
      html_attr("href")
    
    if (length(mens_sports) > 0) {
      womens_sports_df[[name]] <- womens_sports
    } else {
      womens_sports_df[[name]] <- NA
    }
  }, error = function(e) {
    womens_sports_df[[name]] <- NA
    warning(paste("Error occurred for", name, ":", e$message))
  })
}

# Unpack the list column and convert to a DataFrame
womens_sports_df <- womens_sports_df %>%
  enframe(name = "name", value = "womens_sports") %>%
  unnest(womens_sports) 

# Join with the schools_df_2 DataFrame to include the base URL
womens_sports_df <- womens_sports_df %>%
  left_join(schools_df_2, by = "name") %>%
  mutate(gender = "Women's")

# Print the resulting DataFrame
print(womens_sports_df)

```

  
```{r}
library(dplyr)

colnames(mens_sports_df) <- c("school", "sport_url", "main_url", "gender")
colnames(womens_sports_df) <- c("school", "sport_url", "main_url", "gender")


# Join the men's and women's sports DataFrames and add a gender column
all_sports_df <- bind_rows(
  mens_sports_df %>% mutate(gender = "Men's"),
  womens_sports_df %>% mutate(gender = "Women's")
)

# Print the resulting DataFrame
print(all_sports_df)
```

```{r}
# Load the dplyr package
library(dplyr)

# Define a function to extract the desired portion of the URL
extract_url <- function(main_url, sport_url) {
  parts <- unlist(strsplit(main_url, "/"))
  combined_url <- paste(parts[1:3], collapse = "/")
  return(paste0(combined_url, sport_url))
}

# Apply the function to the 'url' column using mutate and rowwise
all_sport_pages <- all_sports_df %>%
  rowwise() %>%
  mutate(combined_url = extract_url(main_url, sport_url))

# Print the updated dataframe
print(all_sport_pages)
```



  
```{r}
library(rvest)
library(dplyr)

mens_results <- list()
womens_results <- list()

for (i in 1:nrow(schools_df_2)) {
  name <- schools_df_2$name[i]
  url <- trimws(schools_df_2$url[i])  # Remove any leading/trailing spaces
  webpage <- read_html(url)
  
  # Scrape Men's sports
  mens_sports <- webpage %>%
    html_nodes(".nested-mobile-menu li:contains(\"Men's\") li.only_link a.color-text") %>%
    html_text(trim = TRUE)
  
  mens_results[[i]] <- data.frame(
    name = name,
    url = url,
    sport = mens_sports,
    gender = "Men's"
  )
  
  # Scrape Women's sports
  womens_sports <- webpage %>%
    html_nodes(".nested-mobile-menu li:contains(\"Women's\") li.only_link a.color-text") %>%
    html_text(trim = TRUE)
  
  womens_results[[i]] <- data.frame(
    name = name,
    url = url,
    sport = womens_sports,
    gender = "Women's"
  )
}

# Combine men's and women's results into a single data frame
combined_results <- bind_rows(mens_results) %>%
  bind_rows(womens_results)




```

```{r}
participating_sports <- combined_results %>%
  group_by(name) %>%
  summarize(
    sport_count=n()
  )
```

mens_womens <- combined_results %>%
  group_by(gender) %>%
  summarize(
    sport_count=n(
    )
  )
```{r}
mens_womens <- combined_results %>%
  group_by(gender) %>%
  summarize(
    sport_count=n(
    )
  )
```

```{r}
gendered_sports <- combined_results %>%
  group_by(name) %>%
  summarise(
    mens = sum(gender == "mens"),
    womens = sum(gender == "womens"),
    total = sum(mens + womens)
  )
```

```{r}
sport_types <- combined_results %>%
  group_by(sport)%>%
  summarize(
    sport_count=n()
  )
```


```{r}

# Initialize an empty list to store results for each school
all_results <- list()

# Iterate over each school
for (i in 1:nrow(schools_df_2)) {
  name <- schools_df_2$name[i]
  url <- trimws(schools_df_2$url[i])  # Remove any leading/trailing spaces
  webpage <- read_html(url)
  
  mens_sports <- webpage %>%
    html_nodes(".nested-mobile-menu li:contains(\"Men's\") li.only_link a.color-text") %>%
    html_text(trim = TRUE)
  
  womens_sports <- webpage %>%
    html_nodes(".nested-mobile-menu li:contains(\"Women's\") li.only_link a.color-text") %>%
    html_text(trim = TRUE)
  
  for (sport in unique(c(mens_sports, womens_sports))) {
    is_mens_sport <- sport %in% mens_sports
    is_womens_sport <- sport %in% womens_sports
    
    if (is_mens_sport) {
      mens_prefix <- ifelse(is_womens_sport & is_mens_sport, "mens-", "")
      sport_url_mens <- paste0(url, "/collections/", tolower(paste0(mens_prefix)), tolower(gsub(" ", "-", sport)))
      all_results[[length(all_results) + 1]] <- data.frame(
        name = name,
        url = url,
        sport = sport,
        gender = "Men's",
        sport_url = sport_url_mens
      )
    }
    
    if (is_womens_sport) {
      womens_prefix <- ifelse(is_womens_sport & !(sport %in% c("Gymnastics", "Equestrian", "Softball")) & !(sport %in% mens_sports), "womens-", "")
      sport_url_womens <- paste0(url, "/collections/", tolower(paste0(womens_prefix)), tolower(gsub(" ", "-", sport)))
      all_results[[length(all_results) + 1]] <- data.frame(
        name = name,
        url = url,
        sport = sport,
        gender = "Women's",
        sport_url = sport_url_womens
      )
    }
  }
}

combined_results_2 <- do.call(rbind, all_results)
  
```
# Print total number of rows
print(nrow(combined_results))

combined_results_2 <- combined_results_2 %>%
  mutate(sport_url = gsub("&-", "", sport_url))
  
  
```{r}
womens_editing <- combined_results_2 %>%
  filter(gender=="Women's") %>%
  mutate(sport_url = gsub("&-", "", sport_url))

mens_editing <- combined_results_2 %>%
  filter(gender=="Men's") %>%
  mutate(sport_url = gsub("&-", "", sport_url))
```
  
  
```{r}
womens_editing$sport_url <- ifelse(
  womens_editing$sport %in% c("Basketball", "Golf", "Track & Field", "Swimming & Diving", "Swimming", "Swim & Dive", "Tennis"),
  gsub("(/collections/)", "\\1womens-", womens_editing$sport_url),
  womens_editing$sport_url
)
  
```
  
```{r}
# Remove trailing spaces from the combined_url column
all_sport_pages$combined_url <- trimws(all_sport_pages$combined_url, which = "right")

# View the resulting dataframe
print(all_sport_pages)
```



```{r}

#she works but was being REAL slow

library(rvest)
library(tidyverse)

# Create a new column for the sport
all_sport_pages_2 <- all_sport_pages %>%
  mutate(sport = NA_character_)

# Extract sport from page title for each URL
for (i in 1:nrow(all_sport_pages)) {
  url <- trimws(all_sport_pages$combined_url[i])
  
  tryCatch({
    html <- read_html(url)
    
    library(rvest)
library(tidyverse)
library(parallel)
library(memoise)  # Add this line

# Determine the number of cores to use
num_cores <- detectCores() - 1  # Use all but one core

# Memoize the read_html function
memoised_read_html <- memoise(read_html)

# Function to process a single row
process_row <- function(row) {
  tryCatch({
    # Use memoised_read_html instead of read_html
    html <- memoised_read_html(row$combined_url)
    
    sport <- html %>%
      html_element("title") %>%
      html_text() %>%
      str_extract("^[^-]+") %>%
      str_trim()
    athletes <- html %>%
      html_elements(".card__heading a") %>%
      html_text() 
    
    tibble(school = row$school, sport = sport, athlete = athletes)
  }, error = function(e) {
    warning(paste("Error occurred for", row$school, ":", e$message))
    tibble(school = row$school, sport = NA_character_, athlete = NA_character_)
  })
}

# Process data in parallel
sport_and_athlete_lists <- mclapply(
  split(all_sport_pages, 1:nrow(all_sport_pages)),
  process_row,
  mc.cores = num_cores
)

# Combine results
sport_and_athlete_df <- bind_rows(sport_and_athlete_lists)
    
```

```{r}
library(rvest)
library(tidyverse)
library(parallel)
library(memoise)

# Create a new column for the sport
all_sport_pages <- all_sport_pages %>%
  mutate(combined_url = trimws(combined_url),
         sport = NA_character_)

# Memoize the read_html function
memoised_read_html <- memoise(read_html)

# Function to extract sport from a URL
extract_sport <- function(url) {
  tryCatch({
    html <- memoised_read_html(url)
    
    sport <- html %>%
      html_element("title") %>%
      html_text() %>%
      str_extract("^[^-]+") %>%
      str_trim()
    
    return(sport)
  }, error = function(e) {
    warning(paste("Error occurred for URL", url, ":", e$message))
    return(NA_character_)
  })
}

# Extract sport for each URL in parallel
num_cores <- detectCores() - 1
sports <- mclapply(all_sport_pages$combined_url, extract_sport, mc.cores = num_cores)

# Add sports to all_sport_pages
all_sport_pages$sport <- unlist(sports)

# Function to process a single row for athletes
process_row <- function(row) {
  tryCatch({
    html <- memoised_read_html(row$combined_url)
    
    athletes <- html %>%
      html_elements(".card__heading a") %>%
      html_text() 
    
    tibble(school = row$school, sport = row$sport, gender=row$gender, athlete = athletes)
  }, error = function(e) {
    warning(paste("Error occurred for", row$school, ":", e$message))
    tibble(school = row$school, sport = row$sport, athlete = NA_character_)
  })
}

# Process data in parallel to get athletes
sport_and_athlete_lists <- mclapply(
  split(all_sport_pages, 1:nrow(all_sport_pages)),
  process_row,
  mc.cores = num_cores
)

# Combine results
sport_and_athlete_df <- bind_rows(sport_and_athlete_lists)
```

```{r}
library(tidyverse)

sport_and_athlete_df_cleaned <- sport_and_athlete_df %>%
  # Clean up the sport column (keep this part as it was)
  mutate(
    sport = str_extract(sport, "^[^–—-]+"),  # Get text before "-", "–", or "—"
    sport = str_remove_all(sport, "Men's|Women's"),  # Remove "Men's" or "Women's"
    sport = str_remove_all(sport, school),  # Remove school name
    sport = str_trim(sport)  # Trim whitespace
  ) %>%
  # Clean up the athlete column (updated part)
  mutate(
    athlete = str_remove(athlete, "\\|.*"),  # Remove "|" and everything after
    athlete = str_remove_all(athlete, "#\\d+"),  # Remove "#" followed by digits
    athlete = str_remove_all(athlete, "\\d+"),  # Remove all digits
    athlete = str_remove_all(athlete, "[#]"),  # Remove any remaining "#"
    athlete = str_trim(athlete),  # Trim whitespace
    athlete = str_squish(athlete)  # Replace multiple spaces with a single space
  ) %>%
  # Remove "Sign Up Now!" and duplicates (keep this part as it was)
  filter(
    athlete != "Sign Up Now!"
  ) %>%
  distinct(school, sport, athlete) %>%
  # Optional: arrange by school and sport for readability
  arrange(school, sport)

# View the first few rows to check the cleaning
head(sport_and_athlete_df_cleaned)
```

```{r}
library(tidyverse)

# Get unique athletes from both dataframes
scraped_athletes <- unique(scraped_results_df_cleaned$data)
cleaned_athletes <- unique(sport_and_athlete_df_cleaned$athlete)

# Find athletes in scraped data but not in cleaned data
missing_athletes <- setdiff(scraped_athletes, cleaned_athletes)

# View the missing athletes
cat("Athletes in scraped data but not in cleaned data:\n")
print(missing_athletes)

# Optional: Get more context about these athletes
context_for_missing <- scraped_results_df_cleaned %>%
  filter(data %in% missing_athletes)

cat("\nContext for missing athletes:\n")
print(context_for_missing)
```

```{r}
library(tidyverse)

scraped_results_df_cleaned <- scraped_results_df %>%
  mutate(
    data = str_trim(data),  # Remove leading/trailing whitespace
    data = case_when(
      str_detect(data, ",") ~ {
        # Split the name into parts
        name_parts <- str_split(data, ", ", simplify = TRUE)
        
        # Recombine as "Firstname Lastname"
        paste(name_parts[, 2], name_parts[, 1])
      },
      TRUE ~ data  # If there's no comma, keep the original
    )
  )

# View the first few rows
head(scraped_results_df_cleaned)
```



```{r}

#THIS WORKS, JUST NAMES
sport_and_athlete_df_2 <- list()
for (i in 1:nrow(all_sport_pages)) {
  name <- all_sport_pages$school[i]
  url <- trimws(all_sport_pages$combined_url[i])
  
  tryCatch({
    html <- read_html(url)
    sport_and_athlete <- html %>%
      html_elements(".card__heading a") %>%
      html_text() 
    
    if (length(sport_and_athlete) > 0) {
      sport_and_athlete_df_2[[i]] <- list(name = name, athlete = sport_and_athlete)
    } else {
      sport_and_athlete_df_2[[i]] <- list(name = name, athlete = NA)
    }
  }, error = function(e) {
    sport_and_athlete_df_2[[i]] <- list(name = name, athlete = NA)
    warning(paste("Error occurred for", name, ":", e$message))
  })
}

# Unpack the list column and convert to a DataFrame
sport_and_athlete_df_2 <- sport_and_athlete_df %>%
  bind_rows()
```

```{r}
library(rvest)
library(tidyverse)

sport_and_athlete_df <- list()
for (i in 1:nrow(all_sport_pages)) {
  school <- all_sport_pages$school[i]
  url <- trimws(all_sport_pages$combined_url[i])
  
  tryCatch({
    html <- read_html(url)
    
    # Extract sport from page title (assuming it's in the format "Sport - School Name")
    sport <- html %>%
      html_element("title") %>%
      html_text() %>%
      str_extract("^[^-]+") %>%
      str_trim()
    
    athletes <- html %>%
      html_elements(".card__heading a") %>%
      html_text() 
    
    if (length(athletes) > 0) {
      sport_and_athlete_df[[i]] <- tibble(school = school, gender = gender, sport = sport, athlete = athletes)
    } else {
      sport_and_athlete_df[[i]] <- tibble(school = school, gender = gender, sport = sport, athlete = NA_character_)
    }
  }, error = function(e) {
    sport_and_athlete_df[[i]] <- tibble(school = school, sport = NA_character_, athlete = NA_character_)
    warning(paste("Error occurred for", school, ":", e$message))
  })
}

# Combine all tibbles into a single dataframe
sport_and_athlete_df <- bind_rows(sport_and_athlete_df)
```
 
```{r}
library(stringi)
library(tidyverse)
library('xml2')
library(rvest)
library(jsonlite)

# Create an empty dataframe to store the scraped data
product_df <- data.frame(name = character(),
                         combined_url = character(),
                         type = character(),
                         title = character(),
                         price = numeric(),
                         stringsAsFactors = FALSE)

# Loop through each URL
for (i in 1:min(236, nrow(athlete_urls))) {
  url <- athlete_urls$combined_url[i]
  # Read the HTML content of the page
  page <- read_html(url)
  
  # Extracting product details from the JavaScript object
  json_data <- page %>%
    html_nodes(xpath = '//script[contains(text(), "productVariants")]') %>%
    html_text()
  
  # Extracting the JSON substring from the JavaScript code
  json_data_clean <- gsub(".*?\\{.*\"productVariants\".*?\\}.*", "\\1", json_data, perl = TRUE)
  
  # Attempt to parse the cleaned JSON data
  tryCatch({
    # Parsing the cleaned JSON data
    product_info <- fromJSON(json_data_clean)
    
    # Extracting relevant product details
    product_subset <- data.frame(
      name = athlete_urls$name[i],
      combined_url = athlete_urls$combined_url[i],
      type = sapply(product_info$productVariants, function(x) x$product$type),
      title = sapply(product_info$productVariants, function(x) x$product$title),
      price = sapply(product_info$productVariants, function(x) x$price$amount)
    )
    
    # Append the product subset to the main dataframe
    product_df <- bind_rows(product_df, product_subset)
  }, error = function(e) {
    # Print the error message
    cat("Error parsing JSON data from URL:", url, "\n")
    # Print the extracted JSON data to inspect
    cat("Extracted JSON data:", json_data_clean, "\n")
  })
}

```
```{r}
library(tidyverse)

sport_and_athlete_df_cleaned <- sport_and_athlete_df %>%
  # Clean up the sport column (keep this part as it was)
  mutate(
    sport = str_extract(sport, "^[^–—-]+"),  # Get text before "-", "–", or "—"
    sport = str_remove_all(sport, "Men's|Women's"),  # Remove "Men's" or "Women's"
    sport = str_remove_all(sport, school),  # Remove school name
    sport = str_trim(sport)  # Trim whitespace
  ) %>%
  # Clean up the athlete column (updated part)
  mutate(
    athlete = str_remove(athlete, "\\|.*"),  # Remove "|" and everything after
    athlete = str_remove_all(athlete, "#\\d+"),  # Remove "#" followed by digits
    athlete = str_remove_all(athlete, "\\d+"),  # Remove all digits
    athlete = str_remove_all(athlete, "[#]"),  # Remove any remaining "#"
    athlete = str_trim(athlete),  # Trim whitespace
    athlete = str_squish(athlete)  # Replace multiple spaces with a single space
  ) %>%
  # Remove "Sign Up Now!" and duplicates (keep this part as it was)
  filter(
    athlete != "Sign Up Now!"
  ) %>%
  distinct(school, sport, athlete, gender) %>%
  # Optional: arrange by school and sport for readability
  arrange(school, sport) %>%
  select(gender, everything())


```


 For athletes on active rosters: 
 
```{r}
sports_participants <- sport_and_athlete_df_cleaned %>%
  group_by(sports) %>%
  summarize(
    number_athletes = n()
  )
```
 
```{r}
athletes
```

